you can make a bundle of source code and dll's using mkbundle.
e.g. 
mkbundle -o main --simlpe main.exe sfuns.dll
which can be run by
./main
Homework will be three steps:
a - 6 points
b - 3 points
c - 1 point 
Linear equations: interesting because 1st term is always linear.
Simplest linear equation: ax=b => x  = 1/a * b. Typically we have system of equations:
A_11 * x_ 1 + A_12 * x_2 = b_1
A_21 * x_1 + A_22 * x_2 = b_2
Or in matrix notation just A * x = b (A is matrix, x and b vectors).
If A is singular (det(A) = 0) there is a solution. Ofcourse we have finite precision, so this is a bit tricky.
Dimitri has already made matrix and vector classes, so we don't need to make these. 
Solve system by triangulization, transform A to T x = b where T can be either upper or lower triangular. Then can be solved easily by back substitution,
last element is known, A_nn * x_n = b_n, the next equation is then A_n-1,n-1 * x_n-1 + A_n-1,n * x_n = b_n-1 but this only has one unknown because we already solved
for x_n.
How to make it triangular? LU decomposition. 
Doolittle algorithm: represent A as L*U (lower and upper), usually choose L as the lower triangle of A with 1's on diagonal and U as rest.
We have 
A x = b
L U x = b
L y = b , y = (U*x)
...
QR decomposition: A = Q * R, Q is orthogonal, Q^T * Q = I. If Q is square and non-singular, Q Q^T = 1.
A x = b
Q R x = b
Q^T Q R x = Q^T b
R x = Q^T b
solve using back substitution (R is upper right triangle)
We have det(A) = det(Q) det(R) 
det(Q^T Q) = det(Q)^2 = 1, det(Q) = +- 1.
How to do QR decomposition? Gram-Schmidt orthogonalalization. Use stabilized/modified Gram-Schmidt. 
...
Calculate inverse matrix 
A * A^-1 = I.
Gives n systems of linear equations. Because yuo look at each column in A^-1 as given rise to a new matrix equation, then solve using previously mentioned methods. 

To find determinant: 
Decompose matrix (n^3) operations, then multiply diagonal together, this is n operations, so order n^3

To find inverse:
Decompose matrix, n^3, backsubstition is n^2 which you have to do once for each column (n), so still order n^3 (but factor 2)

Eigenvalue decomposition
Ax = lx 
A = V D V^T, V is matrix with eigenvectors for columns, D is diagonal matrix with eigenvalues
With V V^T = 1 because V is orthogonal matrix. 
det(A) = dt(V)det(D)det(V^T) = product of eigenvalues
Easily invertible, because 
V D V^T x = b =>
DV^T x = V^T b => 
D is diagonal, finding its inverse is trivial
x = V D^-1 V^T b

Often you want to solve some harmonic oscillator, and the oscillations can be coupled, such that
x'' + A x = 0
Guess x prop to e^(iwt)
-w^2*v + A v = 0
This is eigenvalue problem. If w^2 is < 0, we actually have completely unstable system. w^2 = 0 means disturbances just moves system (?). 

In QM, we often take sin of matrices and such. 
Sin(A) = sum (-1)^k A^k / k!
But this turns into many operations, much easier to work in basis where A is diagonal, then it's simply sin() for each diagonal element. 

This works only for real symmetric matrices.
Otherwise do singular value decomposition
A = U S V, VV^T = 1, V^TV = 1, U^TU=1, S diagonal.
Ax = b
USV x = b
SV x = U^T b 
V x = S^-1 U^T b
x = V^T S^-1 U^T b 

Then V^T S^-1 U^T is pseudo inverse to A, means their product produce a smaller identitymatrix.

How to do eigenvalue decomposition?
Jacobi eigenvalue algorithm.

